%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%% ICML 2016 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Use the following line _only_ if you're still using LaTeX 2.09.
%\documentstyle[icml2016,epsf,natbib]{article}
% If you rely on Latex2e packages, like most moden people use this:
\documentclass{article}

% use Times
\usepackage{times}
% For figures
\usepackage{graphicx} % more modern
%\usepackage{epsfig} % less modern
\usepackage{subfigure}

% For citations
\usepackage{natbib}

% For algorithms
\usepackage{algorithm}
\usepackage{algorithmic}

% Maths
\usepackage{amsmath}
\usepackage{amssymb}

% As of 2011, we use the hyperref package to produce hyperlinks in the
% resulting PDF.  If this breaks your system, please commend out the
% following usepackage line and replace \usepackage{icml2016} with
% \usepackage[nohyperref]{icml2016} above.
\usepackage{hyperref}

% Packages hyperref and algorithmic misbehave sometimes.  We can fix
% this with the following command.
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Employ the following version of the ``usepackage'' statement for
% submitting the draft version of the paper for review.  This will set
% the note in the first column to ``Under review.  Do not distribute.''
\usepackage{icml2016}

% Employ this version of the ``usepackage'' statement after the paper has
% been accepted, when creating the final version.  This will set the
% note in the first column to ``Proceedings of the...''
%\usepackage[accepted]{icml2016}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Deep Manifold Learning on Music Audio for Navigating Large Sound Libraries}

\begin{document}

\twocolumn[
\icmltitle{Deep Manifold Learning on Music Audio \\
           for Navigating Large Sound Libraries}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2016
% package.
\icmlauthor{Eric J. Humphrey}{ejhumphrey@spotify.com}
\icmladdress{Spotify USA,
            620 Avenue of the Americas, New York City, NY 10011 USA}
% \icmlauthor{Your CoAuthor's Name}{email@coauthordomain.edu}
% \icmladdress{Their Fantastic Institute,
%             27182 Exp St., Toronto, ON M6H 2T1 CANADA}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{boring formatting information, machine learning, ICML}

\vskip 0.3in
]

\begin{abstract}

Finding sound for creative purposes is hard because it can be difficult to frame good queries.
% Meta data is sparse, language specific, vocabulary mappings are weird, and ranked
Use data to learn low-dimensional representations for visualization and browsing, discover latent manifolds in the data.


\end{abstract}

\section{Introduction}
\label{submission}

We want to learn low-dimensional representations for visualization and browsing of audio samples for creative purposes.
Discovering latent manifolds and different kinds of projections can help users intuitively make sense of large data collection.

% While many computational approaches have proven useful for various classification or recognition tasks, none directly result in a notion of timbre similarity, a useful concept with a variety of applications.
% % Search with sound; avoids the challenge of articulating queries linguistically.
% One notable instance is the difficulty faced in the search and navigation of large sound sample libraries.
% Queries are predominantly forced to take the form of text, which is problematic for at least two reasons.
% On one hand, it can challenging to describe a specific query semantically, and often metaphors and figurative language are used to relate the experience of a sound;
% a distorted guitar might be referred to as `crunchy', or a trumpet as `bright.'
% Conversely, this kind of descriptive language is far from standardized and varies in meaning from one individual to the next.
% Furthermore, such descriptions are not always associated with every sound in a collection, and typically only at the granularity of the entire recording.
% As a result, the task of navigating a sound library is often reduced to that of an exhaustive, brute force search.


This is a natural application of manifold learning, which typically attempts to preserve one of three relationships in some lower dimensional space: distance, rank-order, or neighborhoods.
Common embedding methods, such as Multidimensional Scaling (MDS) \cite{}, Locally Linear Embedding (LLE) \cite{}, or Isomap \cite{}, adhere to the former, but exhibit two drawbacks in practice.
First, these methods do not yield generalizable mappings that can be readily applied to previously unseen inputs.
Second, and perhaps more importantly, obtaining accurate pairwise distances for a large collection of inputs is not scalable to large datasets.
Rank-ordered embeddings, such as WSABIE \cite{weston2011wsabie}, relax the constraint of precise distance in favor of sorted observations.
This is a slightly easier task, but it may still be necessary to establish a prohibitive number of pairwise comparisons.
Finally, neighborhood methods, such as neighborhood components analysis (NCA) \cite{hinton2004neighborhood}, DrLIM \cite{hadsell2006drlim}, or \texttt{word2vec} \cite{mikolov2013distributed}, simplifiy this further exploiting unordered set relationships.
% \footnote{NCA uses neighbor affinity, which has a similar affect to preserving distances.}
Neighbor relationships between data need not be exhaustive and thus may be easier to obtain, especially from large datasets, or be defined by \emph{a priori} knowledge, \emph{e.g.} class labels.
Notably, prior work has aptly demonstrated the potential for such methods to yield intutitive low-dimensional spaces.

% Local discrimination and non-linear mappings.
Expanding on previous research applying deep networks to the task of timbre similarity \cite{humphrey2015dl4mir}, this work explores the effects of leveraging different neighborhood relationships within a stable formulation.
% Therefore we are interested primarily in how these partitions are defined and sampled during training.
What manifolds exist in the data, and how can we form neighborhood relationships to coax them out?


\section{Approach}

Here we study a class of manifold learning algorithms that aims to preserve or establish contrasting set relationships, \emph{i.e.} neighborhoods, in a low-dimensional space.
Given a collection of observations, $\mathcal{D}$, a contrastive parition, $k$, consists of a positive, $\Gamma_k$, and a negative, $\bar{\Gamma_k}$, subset, satisfying three conditions:
one, contrastive partitions are internally disjoint, $\Gamma_k \cap \bar{\Gamma_k} = \varnothing$;
two, contrastive partitions may comprise a subset of the entire collection, $|\Gamma_k \cup \bar{\Gamma_k}| \le |\mathcal{D}|$;
and three, contrastive partitions are drawn independently of each other, such that any two partitions, $i$ and $j$, may share observations, $|\Gamma_i \cap \Gamma_j| \ge 0$.
This is achived by leveraging a parameterized, non-linear function, \emph{e.g.} a convolutional neural network, that maps high dimensional data into the target embedding space.
The parameters are optimized to make the distance of neighbors small and non-neighbors large, and the resulting model can then be evaluated on a hold-out set.


\subsection{Model}

Audio is first transformed to a constant-Q representation, parameterized as follows:
signals are downsampled to 16kHz;
bins are spaced at 24 per octave, or quarter-tone resolution, and span eight octaves, from 27.5Hz to 7040Hz;
analysis is performed at a framerate of 20Hz uniformly across all frequency bins.
Logarithmic compression is applied to the frequency coefficients with an offset of one, i.e. $log(C*X + 1.0)$, where we set $C=50$.

Following the work presented in \cite{humphrey2015dl4mir}, 500ms windows of time-frequency coefficients are transformed by a five-layer convolutional neural network, consisting of three 3D-convolutional layers and two fully connected layers.
Max-pooling by a factor of 2 is used along time in first two layers.
The first four layers use hyperbolic tangent activation functions, while the last layer is linear to avoid saturation.
The final output is 3-dimensional for visualization purposes.


\subsection{Training Strategy}

% Loss architecture
Similar to some work in the application of deep networks for metric learning \cite{hadsell2006drlim, humphrey2011nlse, humphrey2015dl4mir}, we use a contrastive loss term to draw neighborhoods together and push dissimilar observations away.
However, we augment training criterion to use a ternary network configuration, rather than the pairwise harness employed previously, defined as follows:

% loss_sim = hwr(cost_sim - margin_sim)^2
% loss_diff = hwr(margin_diff - cost_diff)^2
% total = ave(loss_sim + loss_diff)
\begin{align*}
Z_i = \mathcal{F}(X_i | \Theta), Z_p = \mathcal{F}(X_p | \Theta), Z_n = \mathcal{F}(X_n | \Theta)\\
D_p = || Z_i - Z_p ||_2, D_n = || Z_i - Z_n ||_2\\
\mathcal{L} = \max(0, D_p^2 - m_{p}) + \max(0, m_{n} - D_n)^2 \\
\end{align*}

Here, three inputs -- $X_i, X_p, X_n$ -- are transformed by the model, $\mathcal{F}$, given the same parameters, $\Theta$.
These observations are chosen such that $X_i, X_p \in \Gamma_k$ and $X_n \in \bar{\Gamma_k}$.
Euclidean distance is computed between the positive and negative embedding pairs, and two margins, $m_p$ and $m_n$, define a floor on the positive and negative loss terms.

\subsection{Data}

The data source used herein is drawn from the Vienna Symphonic Library (VSL), a massive collection of studio-grade orchestral instrument samples recorded over a variety of performance techniques\footnote{\url{https://vsl.co.at/en}}.
We leverage a previously sampled collection \cite{humphrey2015dl4mir}, comprised of 5k samples drawn from 24 of the largest instrument classes.
The set is partitioned into 72k, 18k, and 30k for training, validation, and testing, respectively.

As discussed above, the crux of this exploration lies in \emph{how} neighborhoods are defined and sampled for training.
We consider a number of options in order to explore what manifolds or behaviors might reveal themselves in the data:
(1) nearest neighbors in the input space;
(2) instrument class;
(3) absolute pitch;
% \item Pitch chroma
(4) instrument class and absolute pitch;
(5) instrument class and absolute pitch, $\pm~2$.
% \item Instrument class and pitch chroma


\section{Experimental Results}

All training runs proceed for 50k iterations.


% \begin{figure}[ht]
% \vskip 0.2in
% \begin{center}
% \centerline{\includegraphics[width=\columnwidth]{icml_numpapers}}
% \caption{Historical locations and number of accepted papers for International
%   Machine Learning Conferences (ICML 1993 -- ICML 2008) and
%   International Workshops on Machine Learning (ML 1988 -- ML
%   1992). At the time this figure was produced, the number of
%   accepted papers for ICML 2008 was unknown and instead estimated.}
% \label{icml-historical}
% \end{center}
% \vskip -0.2in
% \end{figure}

% Quantitative
Interpretable embeddings.
Nearest neighbor analysis quantitatively show the defined partitions are preserved.

% Qualitative
Follow trajectories of sounds in 3-space.
Concatenative synthesis, qualitative analysis.



\section{Conclusions}

We have explored


Number figures sequentially, placing the figure number and caption
{\it after\/} the graphics, with at least 0.1~inches of space before
the caption and 0.1~inches after it, as in
Figure~\ref{icml-historical}.  The figure caption should be set in
9~point type and centered unless it runs two or more lines, in which
case it should be flush left.  You may float figures to the top or
bottom of a column, and you may set wide figures across both columns
(use the environment {\tt figure*} in \LaTeX), but always place
two-column figures at the top or bottom of the page.


% Acknowledgements should only appear in the accepted version.
% \section*{Acknowledgements}

% \textbf{Do not} include acknowledgements in the initial version of
% the paper submitted for blind review.

% If a paper is accepted, the final camera-ready version can (and
% probably should) include acknowledgements. In this case, please
% place such acknowledgements in an unnumbered section at the
% end of the paper. Typically, this will include thanks to reviewers
% who gave useful comments, to colleagues who contributed to the ideas,
% and to funding agencies and corporate sponsors that provided financial
% support.


% In the unusual situation where you want a paper to appear in the
% references without citing it in the main text, use \nocite
% \nocite{langley00}

\bibliography{example_paper}
\bibliographystyle{icml2016}

\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was
% created by Lise Getoor and Tobias Scheffer, it was slightly modified
% from the 2010 version by Thorsten Joachims & Johannes Fuernkranz,
% slightly modified from the 2009 version by Kiri Wagstaff and
% Sam Roweis's 2008 version, which is slightly modified from
% Prasad Tadepalli's 2007 version which is a lightly
% changed version of the previous year's version by Andrew Moore,
% which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
